{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "616aade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all the important libraries\n",
    "import glob\n",
    "import pympi\n",
    "from io import open\n",
    "from conllu import parse_incr, parse\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "61987a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to find different patterns of Reference numbers(annotation numbers since we have to merge some sentences)\n",
    "def search_annotation_pattern2(sent_id):\n",
    "    if re.search(\"\\d{1,4}$\", sent_id):\n",
    "        m = re.search(\"\\d{1,4}$\", sent_id)\n",
    "        return(sent_id, \"a\" + str(m.group()))\n",
    "    else:\n",
    "        pass\n",
    "def search_annotation_pattern1(sent_id):\n",
    "    if re.search(\"\\d{1,4}\\:\\d{1,4}$\", sent_id):\n",
    "        m = re.search(\"\\d{1,4}\\:\\d{1,4}$\", sent_id)\n",
    "        return(sent_id, \"a\" + str(m.group().split(\":\")[0]))\n",
    "    else:\n",
    "        return(search_annotation_pattern2(sent_id))\n",
    "\n",
    "def search_annotation_pattern(sent_id):\n",
    "    if re.search(\"\\d{1,4}\\.\\d{1,4}$\", sent_id):\n",
    "        m = re.search(\"\\d{1,4}\\.\\d{1,4}$\", sent_id)\n",
    "#         n = m.group()\n",
    "#         s1, s2 = n.split(\".\")\n",
    "#         s = s1 + \":\" + s2\n",
    "        return(sent_id, \"a\" + str(m.group().split(\".\")[0]))\n",
    "    else:\n",
    "        return(search_annotation_pattern1(sent_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acddb431",
   "metadata": {},
   "source": [
    "## Matching the sentences on the basis of Annotation Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e5aeb98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eaf_file_list = glob.glob(\"/Users/ashish/Desktop/Computation Linguistics Project/Pueble-Nahuatl-Manifest/ELAN-files-Final-proofed-and-most-translated/*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "3e0d12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speach import elan\n",
    "ann_no_with_time = [] \n",
    "for file in eaf_file_list:\n",
    "    file_name = file.split('/')[-1]\n",
    "    eaf = elan.read_eaf(file)\n",
    "    for tier in eaf:\n",
    "        for ann in tier:\n",
    "            ann_no_with_time.append([ann.ID, ann, ann.from_ts, ann.to_ts, file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "96d77399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data_eaf_ann = pd.DataFrame(ann_no_with_time, columns = [\"ann_no\",\"sentence\", \"start_time\", \"end_time\", \"eaf_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "23b8244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data_conllu = pd.DataFrame(columns = [\"sentence\", \"sent_id\", \"ann_no\"])\n",
    "data_list = []\n",
    "conllu_file = open(\"/Users/ashish/Desktop/Computation Linguistics Project/apertium-azz/corpora/azz_itml-ud-test.conllu\", \"r\", encoding=\"utf-8\")\n",
    "for tokenlist in parse_incr(conllu_file):\n",
    "    data = tokenlist.metadata\n",
    "    data_list.append(data)\n",
    "    sentence = tokenlist.metadata['text']\n",
    "    sent_id = tokenlist.metadata['sent_id']\n",
    "    sentence_data_conllu = sentence_data_conllu.append({\"sentence\":sentence, \"sent_id\":search_annotation_pattern(sent_id)[0],\n",
    "                                         \"ann_no\":search_annotation_pattern(sent_id)[1]}, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e6c4fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1227/1227 [1:17:54<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "ann_time = []\n",
    "for c in tqdm(sentence_data_conllu.index):\n",
    "    for e in sentence_data_eaf_ann.index:\n",
    "        if (sentence_data_eaf_ann.iloc[e].eaf_file in sentence_data_conllu.iloc[c].sent_id):\n",
    "            if(sentence_data_eaf_ann.iloc[e].ann_no == sentence_data_conllu.iloc[c].ann_no):\n",
    "                ann_time.append([sentence_data_conllu.iloc[c].ann_no, sentence_data_eaf_ann.iloc[e].start_time, sentence_data_eaf_ann.iloc[e].end_time, sentence_data_conllu.iloc[c].sentence])\n",
    "\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "2c398fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_time_df = pd.DataFrame(ann_time, columns = [\"annotation_no\", \"start_time\", \"end_time\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9fda2",
   "metadata": {},
   "source": [
    "### Removing sentences already matched in above step and performing sentence matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "6342d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing conllu test file to read all the sentences we have to match in EAF files\n",
    "data_list = []\n",
    "conllu_file = open(\"/Users/ashish/Desktop/Computation Linguistics Project/apertium-azz/corpora/azz_itml-ud-test.conllu\", \"r\", encoding=\"utf-8\")\n",
    "for tokenlist in parse_incr(conllu_file):\n",
    "    data = tokenlist.metadata\n",
    "    data_list.append(data)\n",
    "data_df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "f61e7605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/hglj_fjs6n5gn9jr00v55str0000gn/T/ipykernel_67999/2279775885.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_conllu[\"ann_no\"] = ann_no\n"
     ]
    }
   ],
   "source": [
    "#Selecting important columns and extracting only \n",
    "sentence_conllu = data_df.iloc[:,0:5]\n",
    "ann_no = []\n",
    "for i in range(len(sentence_conllu)):\n",
    "    ann = search_annotation_pattern(sentence_conllu.loc[i, \"sent_id\"])[1]\n",
    "    ann_no.append(ann)\n",
    "sentence_conllu[\"ann_no\"] = ann_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "db1a831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing already identified sentences from the conllu list\n",
    "l = []\n",
    "for i in sentence_conllu.index:\n",
    "    for j in ann_time_df.index:\n",
    "        if(ann_time_df.iloc[j].annotation_no == sentence_conllu.iloc[i].ann_no and ann_time_df.iloc[j].sentence == sentence_conllu.iloc[i].text):\n",
    "            l.append(i)\n",
    "sentence_data_c = sentence_conllu.drop(index = l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "43e30938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get sent id\n",
    "def sent(sent_id):\n",
    "    if len(sent_id.split(\":\")) == 4:\n",
    "        sent_id = sent_id.split(\":\")[0]\n",
    "    elif len(sent_id.split(\":\")) == 3:\n",
    "        sent_id = sent_id.split(\":\")[0]\n",
    "    else:\n",
    "        sent_id = sent_id.split(\":\")[0]\n",
    "    \n",
    "    return sent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "6ff116cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text[orig]</th>\n",
       "      <th>text[spa]</th>\n",
       "      <th>labels</th>\n",
       "      <th>ann_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>¿Keniuj Mochijchiuaj ne Sitalimej?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>¿Cómo se forman las estrellas?</td>\n",
       "      <td>complete</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Se youal keman takistok uan amo metstona, itec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>En una noche despejada y sin luna, desde el ca...</td>\n",
       "      <td>complete-tree check-mark</td>\n",
       "      <td>a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Neje sitalimej no chijchiujtokej kemej ne tona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estas estrellas son similares a nuestro sol, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Nijin ijpotok uan mixuak mololouaj, nejin teyi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Esos ingredientes van formando grumos que van ...</td>\n",
       "      <td>complete-tree</td>\n",
       "      <td>a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Ijkuak miki, ne sitalin toponi uan seki átomos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Al morir, las estrellas explotan y parte de lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sent_id  \\\n",
       "0  kiteixmatiltijtok-tamachilis   \n",
       "1  kiteixmatiltijtok-tamachilis   \n",
       "2  kiteixmatiltijtok-tamachilis   \n",
       "3  kiteixmatiltijtok-tamachilis   \n",
       "4  kiteixmatiltijtok-tamachilis   \n",
       "\n",
       "                                                text text[orig]  \\\n",
       "0                 ¿Keniuj Mochijchiuaj ne Sitalimej?        NaN   \n",
       "1  Se youal keman takistok uan amo metstona, itec...        NaN   \n",
       "2  Neje sitalimej no chijchiujtokej kemej ne tona...        NaN   \n",
       "3  Nijin ijpotok uan mixuak mololouaj, nejin teyi...        NaN   \n",
       "4  Ijkuak miki, ne sitalin toponi uan seki átomos...        NaN   \n",
       "\n",
       "                                           text[spa]  \\\n",
       "0                     ¿Cómo se forman las estrellas?   \n",
       "1  En una noche despejada y sin luna, desde el ca...   \n",
       "2  Estas estrellas son similares a nuestro sol, a...   \n",
       "3  Esos ingredientes van formando grumos que van ...   \n",
       "4  Al morir, las estrellas explotan y parte de lo...   \n",
       "\n",
       "                     labels ann_no  \n",
       "0                  complete     a1  \n",
       "1  complete-tree check-mark     a3  \n",
       "2                       NaN     a4  \n",
       "3             complete-tree     a6  \n",
       "4                       NaN    a10  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_data_conllu = sentence_data_c.reset_index(drop = True)\n",
    "for i in sentence_data_conllu.index:\n",
    "    sentence_data_conllu.iloc[i][\"sent_id\"] = sent(sentence_data_conllu.iloc[i][\"sent_id\"])\n",
    "sentence_data_conllu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "3328163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_data_conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "89693c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get spanish tiers\n",
    "def get_spanish_tiers(eaf):\n",
    "    #gettting tier names to collect data using tier name\n",
    "    tiers = eaf.get_tier_names()\n",
    "    #selecting tier names for spanish sentences\n",
    "    tiers_spanish = []\n",
    "    #for loop to obtain all the spanish translations\n",
    "    #As for one eaf file spanish translation could be done by various persons\n",
    "    #\"Traducción\" is the spanish word for translation, so selecting tier on basis of that.\n",
    "    for i in tiers:\n",
    "        if(\"Traducción\" in i):\n",
    "            tiers_spanish.append(i)\n",
    "    return(tiers_spanish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "68bc510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get sentences for all the spanish tier ids\n",
    "def get_spanish_sentences(eaf):\n",
    "    #extracting spanish sentences\n",
    "    tiers_spanish = get_spanish_tiers(eaf)\n",
    "    \n",
    "    #empty space holders to collect the data\n",
    "    data = []\n",
    "\n",
    "    #For loop to get data for all the IDs in each file\n",
    "    for i in range(len(tiers_spanish)):\n",
    "        data = data + eaf.get_annotation_data_for_tier(tiers_spanish[i])\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "faaae40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing all the files using eaf and storing all the sentences in same dataframe\n",
    "all_data = []\n",
    "for i in range(len(eaf_file_list)):\n",
    "    file_name = eaf_file_list[i].split('/')[-1]\n",
    "    eaf = pympi.Elan.Eaf(eaf_file_list[i])\n",
    "    a = eaf.get_linked_files()\n",
    "    media_file_link = a[0][\"MEDIA_URL\"]\n",
    "    media_file_name = media_file_link.split('/')[-1]\n",
    "    sentences = get_spanish_sentences(eaf)\n",
    "    for j in range(len(sentences)):\n",
    "        l = list(sentences[j])\n",
    "        l.insert(len(l),file_name)\n",
    "        l.insert(len(l), media_file_name)\n",
    "        sentences[j] = tuple(l)\n",
    "    all_data = all_data + sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "a3ad292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data_eaf = pd.DataFrame(all_data, columns = [\"start_time\", \"end_time\", \"sentence\", \"org\", \"eaf_file_name\", \"audio_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "0eeb5b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>org</th>\n",
       "      <th>eaf_file_name</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5737</td>\n",
       "      <td>Pues puedes decirme si conoces esta</td>\n",
       "      <td>Pos kwali tine:chili:s, ne:n, katí:n tiki:xmat...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5737</td>\n",
       "      <td>11688</td>\n",
       "      <td>hierbita este tapits..., la que dices que se u...</td>\n",
       "      <td>xiwtsí:n ne:n [ta]pi:ts..., tikihtowa ika kini...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79909</td>\n",
       "      <td>85222</td>\n",
       "      <td>Vienen, este, bueno, la serpiente sale del lug...</td>\n",
       "      <td>Wi:tseh, ne:n, *bueno** wa:le:wa ne:n kowa:t w...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101415</td>\n",
       "      <td>104620</td>\n",
       "      <td>Y cómo saben, vienen escuchando o</td>\n",
       "      <td>Wa:n ki:ní:n kimatih, ika, wi:tseh kikaktiwi:t...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104620</td>\n",
       "      <td>106161</td>\n",
       "      <td>Se buscan.</td>\n",
       "      <td>Mote:mowah.</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "      <td>Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  end_time                                           sentence  \\\n",
       "0           0      5737                Pues puedes decirme si conoces esta   \n",
       "1        5737     11688  hierbita este tapits..., la que dices que se u...   \n",
       "2       79909     85222  Vienen, este, bueno, la serpiente sale del lug...   \n",
       "3      101415    104620                  Y cómo saben, vienen escuchando o   \n",
       "4      104620    106161                                         Se buscan.   \n",
       "\n",
       "                                                 org  \\\n",
       "0  Pos kwali tine:chili:s, ne:n, katí:n tiki:xmat...   \n",
       "1  xiwtsí:n ne:n [ta]pi:ts..., tikihtowa ika kini...   \n",
       "2  Wi:tseh, ne:n, *bueno** wa:le:wa ne:n kowa:t w...   \n",
       "3  Wa:n ki:ní:n kimatih, ika, wi:tseh kikaktiwi:t...   \n",
       "4                                        Mote:mowah.   \n",
       "\n",
       "                                       eaf_file_name  \\\n",
       "0  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...   \n",
       "1  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...   \n",
       "2  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...   \n",
       "3  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...   \n",
       "4  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...   \n",
       "\n",
       "                                          audio_file  \n",
       "0  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...  \n",
       "1  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...  \n",
       "2  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...  \n",
       "3  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...  \n",
       "4  Tzina_Botan_JVC313-AND308_kowaatapiitsxiwit-Ar...  "
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_data_eaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "8eb75c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "sdee = deepcopy(sentence_data_eaf)\n",
    "sdcc = deepcopy(sentence_data_conllu)\n",
    "\n",
    "sentence = set()\n",
    "from collections import defaultdict\n",
    "is_sde_used = defaultdict(lambda: False)\n",
    "is_sdc_used = defaultdict(lambda: False)\n",
    "\n",
    "for sde in sdee.itertuples():\n",
    "    is_sde_used[(sde)] = False\n",
    "    \n",
    "for sdc in sdcc.itertuples():\n",
    "    is_sdc_used[(sdc)] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e1ed1",
   "metadata": {},
   "source": [
    "The below code is to compare the sent_id and text of eaf file with conllu files(in the first for loop).\n",
    "In the second for loop we have same snetences repeated many times and we cannot distinguish them with sent_id, so I am just assigning the time I am getting for the first search value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9456427",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sdc in sdcc.itertuples():\n",
    "    if not is_sdc_used[(sdc)]:\n",
    "        for sde in sdee.itertuples():\n",
    "            if not is_sde_used[(sde)]:\n",
    "                if sdc[4] == sde[3]:\n",
    "                    if sde[5] in sdc[1]:\n",
    "                        sentence.add((sdc[6], sde[1], sde[2], sde[3]))\n",
    "                        is_sde_used[(sde)] = True\n",
    "                        is_sdc_used[(sdc)] = True\n",
    "                        break\n",
    "\n",
    "\n",
    "for sdc in sdcc.itertuples():\n",
    "    if not is_sdc_used[(sdc)]:\n",
    "        for sde in sdee.itertuples():\n",
    "            if not is_sde_used[(sde)]:\n",
    "                if sdc[4] == sde[3]:\n",
    "                    sentence.add((sdc[6], sde[1], sde[2], sde[3]))\n",
    "                    is_sde_used[(sde)] = True\n",
    "                    is_sdc_used[(sdc)] = True\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "8645a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "# count_sde = 0 \n",
    "# for i in is_sde_used.values():\n",
    "#     if i == True:\n",
    "#         count_sde += 1\n",
    "        \n",
    "# count_sdc = 0 \n",
    "# for i in is_sdc_used.values():\n",
    "#     if i == True:\n",
    "#         count_sdc += 1\n",
    "# print(count_sde, count_sdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "3a097b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_time_df = pd.DataFrame(sentence, columns = [\"annotation_no\", \"start_time\", \"end_time\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "85907b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text[orig]</th>\n",
       "      <th>text[spa]</th>\n",
       "      <th>labels</th>\n",
       "      <th>ann_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>¿Keniuj Mochijchiuaj ne Sitalimej?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>¿Cómo se forman las estrellas?</td>\n",
       "      <td>complete</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Se youal keman takistok uan amo metstona, itec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>En una noche despejada y sin luna, desde el ca...</td>\n",
       "      <td>complete-tree check-mark</td>\n",
       "      <td>a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Neje sitalimej no chijchiujtokej kemej ne tona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estas estrellas son similares a nuestro sol, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Nijin ijpotok uan mixuak mololouaj, nejin teyi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Esos ingredientes van formando grumos que van ...</td>\n",
       "      <td>complete-tree</td>\n",
       "      <td>a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiteixmatiltijtok-tamachilis</td>\n",
       "      <td>Ijkuak miki, ne sitalin toponi uan seki átomos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Al morir, las estrellas explotan y parte de lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sent_id  \\\n",
       "0  kiteixmatiltijtok-tamachilis   \n",
       "1  kiteixmatiltijtok-tamachilis   \n",
       "2  kiteixmatiltijtok-tamachilis   \n",
       "3  kiteixmatiltijtok-tamachilis   \n",
       "4  kiteixmatiltijtok-tamachilis   \n",
       "\n",
       "                                                text text[orig]  \\\n",
       "0                 ¿Keniuj Mochijchiuaj ne Sitalimej?        NaN   \n",
       "1  Se youal keman takistok uan amo metstona, itec...        NaN   \n",
       "2  Neje sitalimej no chijchiujtokej kemej ne tona...        NaN   \n",
       "3  Nijin ijpotok uan mixuak mololouaj, nejin teyi...        NaN   \n",
       "4  Ijkuak miki, ne sitalin toponi uan seki átomos...        NaN   \n",
       "\n",
       "                                           text[spa]  \\\n",
       "0                     ¿Cómo se forman las estrellas?   \n",
       "1  En una noche despejada y sin luna, desde el ca...   \n",
       "2  Estas estrellas son similares a nuestro sol, a...   \n",
       "3  Esos ingredientes van formando grumos que van ...   \n",
       "4  Al morir, las estrellas explotan y parte de lo...   \n",
       "\n",
       "                     labels ann_no  \n",
       "0                  complete     a1  \n",
       "1  complete-tree check-mark     a3  \n",
       "2                       NaN     a4  \n",
       "3             complete-tree     a6  \n",
       "4                       NaN    a10  "
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_data_conllu = sentence_data_c.reset_index(drop = True)\n",
    "for i in sentence_data_conllu.index:\n",
    "    sentence_data_conllu.iloc[i][\"sent_id\"] = sent(sentence_data_conllu.iloc[i][\"sent_id\"])\n",
    "sentence_data_conllu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "fdb346b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_data_conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "1d7843a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sent(data):\n",
    "    dicto = defaultdict(lambda: [])\n",
    "    for _ in data:\n",
    "        dicto[_[1]].append(_[0])\n",
    "    data = []\n",
    "    for key, val in dicto.items():\n",
    "        data.append((' '.join(val), key))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "9f761ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_id = sentence_data_conllu.groupby(\"sent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "818b9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]\n",
    "for id in sentence_data_conllu.sent_id.unique():\n",
    "    df_new = df_sent_id.get_group(id)\n",
    "    df_new1 = df_new[[\"text\", \"ann_no\"]]\n",
    "    data = df_new1.values.tolist()\n",
    "    for i in range(len(data)):\n",
    "        data[i][0] = str(data[i][0])\n",
    "    data = merge_sent(data)\n",
    "    data_df = pd.DataFrame(data, columns = [\"sentence\", \"ann_no\"])\n",
    "    df = df_new.merge(right = data_df, on = \"ann_no\")\n",
    "    frames = frames + df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "84b4dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data_conllu = pd.DataFrame(frames, columns = ['sent_id', 'text', 'text[org]', 'text[spa]', 'labels', 'ann_no', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "670d8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "sdee = deepcopy(sentence_data_eaf)\n",
    "sdcc = deepcopy(sentence_data_conllu)\n",
    "\n",
    "sentence = set()\n",
    "from collections import defaultdict\n",
    "is_sde_used = defaultdict(lambda: False)\n",
    "is_sdc_used = defaultdict(lambda: False)\n",
    "\n",
    "for sde in sdee.itertuples():\n",
    "    is_sde_used[(sde)] = False\n",
    "    \n",
    "for sdc in sdcc.itertuples():\n",
    "    is_sdc_used[(sdc)] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca674d48",
   "metadata": {},
   "source": [
    "As we did for the above step we are doing same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "fc7d851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sdc in sdcc.itertuples():\n",
    "    if not is_sdc_used[(sdc)]:\n",
    "        for sde in sdee.itertuples():\n",
    "            if not is_sde_used[(sde)]:\n",
    "                if sdc[7] == sde[3]:\n",
    "                    if sde[5] in sdc[1]:\n",
    "                        sentence.add((sdc[6], sde[1], sde[2], sde[3]))\n",
    "                        is_sde_used[(sde)] = True\n",
    "                        is_sdc_used[(sdc)] = True\n",
    "                        break\n",
    "\n",
    "\n",
    "for sdc in sdcc.itertuples():\n",
    "    if not is_sdc_used[(sdc)]:\n",
    "        for sde in sdee.itertuples():\n",
    "            if not is_sde_used[(sde)]:\n",
    "                if sdc[7] == sde[3]:\n",
    "                    sentence.add((sdc[6], sde[1], sde[2], sde[3]))\n",
    "                    is_sde_used[(sde)] = True\n",
    "                    is_sdc_used[(sdc)] = True\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5fa50d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 354\n"
     ]
    }
   ],
   "source": [
    "count_sde = 0 \n",
    "for i in is_sde_used.values():\n",
    "    if i == True:\n",
    "        count_sde += 1\n",
    "        \n",
    "count_sdc = 0 \n",
    "for i in is_sdc_used.values():\n",
    "    if i == True:\n",
    "        count_sdc += 1\n",
    "print(count_sde, count_sdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c538910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_merge_df = pd.DataFrame(sentence, columns = [\"annotation_no\", \"start_time\", \"end_time\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "7fbd3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "0611c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [sent_merge_df, sent_time_df, ann_time_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "2c834e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "4be3ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set_meta method of pyconll to write back to conllu files with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c927947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "d59829a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_file_path = \"/Users/ashish/Desktop/Computation Linguistics Project/apertium-azz/corpora/test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "acc0a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pyconll.load_from_file(conll_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7044a0",
   "metadata": {},
   "source": [
    "The below for loops are assigning start time and end time to sentences we have accumulated in the above steps to the test conllu file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "88f6895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting start time and end time for the texts\n",
    "for i in final_data.index:\n",
    "    for sentence in test:\n",
    "        if sentence.meta_present(\"labels\"):\n",
    "            ann_no = sentence.meta_value(\"labels\").split(\" \")[0]\n",
    "            sent = sentence.meta_value(\"text\")\n",
    "            if (sent == final_data.iloc[i].sentence and ann_no == final_data.iloc[i].annotation_no):\n",
    "                sentence.set_meta(\"start_time\", final_data.iloc[i].start_time)\n",
    "                sentence.set_meta(\"end_time\", final_data.iloc[i].start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "b208e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting start time and end time for the text in spanish\n",
    "for i in final_data.index:\n",
    "    for sentnece in test:\n",
    "        if not sentence.meta_present(\"start_time\"):\n",
    "            if sentence.meta_present(\"text[spa]\"):\n",
    "                if (sent == final_data.iloc[i].sentence):\n",
    "                    sentence.set_meta(\"start_time\", final_data.iloc[i].start_time)\n",
    "                    sentence.set_meta(\"end_time\", final_data.iloc[i].start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
